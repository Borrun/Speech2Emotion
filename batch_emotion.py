from funasr import AutoModel
import json
from pathlib import Path
from collections import Counter
import matplotlib.pyplot as plt
from tqdm import tqdm
import pandas as pd
import re

# ---------------- é…ç½® ----------------
AUDIO_DIR = Path("/Users/Zhuanz1/Speech2Emotion/wavs")
SCP_PATH = AUDIO_DIR / "wav.scp"
OUTPUT_JSON = Path("/Users/Zhuanz1/Speech2Emotion/emotion_results.json")
OUTPUT_CSV = Path("/Users/Zhuanz1/Speech2Emotion/emotion_results.csv")
OUTPUT_PLOT = Path("/Users/Zhuanz1/Speech2Emotion/emotion_distribution.png")

BATCH_SIZE = 8
DEVICE = "mps"  # æˆ– "cpu"
HUB = "hf"      # SenseVoiceSmall ç”¨ hf æ›´ç¨³å®š
# ---------------- é…ç½® ----------------

def generate_wav_scp_if_needed():
    if not SCP_PATH.exists():
        print("wav.scp ä¸å­˜åœ¨ï¼Œæ­£åœ¨è‡ªåŠ¨ç”Ÿæˆ...")
        wav_files = sorted(AUDIO_DIR.glob("*.wav"))
        if not wav_files:
            raise FileNotFoundError(f"æ–‡ä»¶å¤¹ {AUDIO_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .wav æ–‡ä»¶ï¼")
        with open(SCP_PATH, "w", encoding="utf-8") as f:
            for wav in wav_files:
                utt_id = wav.stem
                f.write(f"{utt_id} {wav.absolute()}\n")
        print(f"å·²ç”Ÿæˆ wav.scpï¼ŒåŒ…å« {len(wav_files)} æ¡éŸ³é¢‘")

def main():
    generate_wav_scp_if_needed()

    print("åŠ è½½ SenseVoiceSmall æ¨¡å‹ï¼ˆå·²ä¸‹è½½æˆåŠŸï¼Œå»æ‰ VAD é¿å…æ³¨å†Œé—®é¢˜ï¼‰...")
    try:
        model = AutoModel(
            model="FunAudioLLM/SenseVoiceSmall",  # HF å®˜æ–¹ repoï¼Œå·²ä¸‹è½½æˆåŠŸ
            hub=HUB,
            device=DEVICE,
            trust_remote_code=True,
            disable_update=True,
            # å»æ‰ vad_modelï¼Œé¿å… 'fsmn-vad is not registered' é”™è¯¯
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        return

    print(f"å¼€å§‹æ‰¹é‡æ¨ç†ï¼ˆ{DEVICE}, batch_size={BATCH_SIZE}ï¼‰...")

    res = model.generate(
        input=str(SCP_PATH),
        batch_size=BATCH_SIZE,
        language="auto",      # è‡ªåŠ¨æ£€æµ‹ä¸­æ–‡
        use_itn=True,         # æ•°å­—è½¬å†™
        # æ— éœ€ merge_vadï¼ŒSenseVoiceSmall è‡ªå¸¦ VAD
    )

    results = []
    emotions = []

    print("å¤„ç† SenseVoice è¾“å‡ºï¼ˆæå– <|EMOTION|> tokenï¼‰...")
    emotion_map = {
        "happy": "happy", "sad": "sad", "angry": "angry", "neutral": "neutral",
        "fear": "fearful", "fearful": "fearful", "disgust": "disgusted", 
        "surprise": "surprised", "surprised": "surprised", "unk": "unknown"
    }

    for item in tqdm(res, desc="ä¿å­˜ç»“æœ", unit="audio"):
        utt_id = item.get("key", item.get("utt", "unknown"))
        text = item.get("text", "")
        
        # SenseVoice è¾“å‡ºç¤ºä¾‹ï¼š'<|zh|><|neutral|>ä½ å¥½ä¸–ç•Œ' æˆ– '<|HAPPY|>hello'
        emo_match = re.search(r'<\|([A-Z]+)\|>', text, re.IGNORECASE)
        emo_raw = emo_match.group(1).lower() if emo_match else "unknown"
        emo = emotion_map.get(emo_raw, emo_raw if emo_raw != "unk" else "unknown")
        
        # æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤æ‰€æœ‰ <|token|>
        clean_text = re.sub(r'<\|[^>]+>', '', text).strip()
        
        # SenseVoice æ˜¯ hard labelï¼Œscore è®¾ä¸º 1.0ï¼ˆåæœŸå¯åŠ ç½®ä¿¡åº¦ï¼‰
        score = 1.0

        results.append({
            "utt_id": utt_id,
            "wav": f"{utt_id}.wav",
            "emotion": emo,
            "score": score,
            "transcription": clean_text[:200] + "..." if len(clean_text) > 200 else clean_text
        })
        emotions.append(emo)

    # è°ƒè¯•è¾“å‡º
    print("\nğŸ” è°ƒè¯• - å‰ 3 æ¡å®Œæ•´åŸå§‹è¾“å‡ºï¼š")
    for i, item in enumerate(res[:3], 1):
        print(f"ç¬¬{i}æ¡ raw: key='{item.get('key')}', text='{item.get('text', '')[:100]}...'")
        print(f"   â†’ emotion='{results[i-1]['emotion']}', text='{results[i-1]['transcription']}'")

    # ä¿å­˜ JSON
    with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON: {OUTPUT_JSON}")

    # ä¿å­˜ CSV
    df = pd.DataFrame(results)
    df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
    print(f"âœ… CSV: {OUTPUT_CSV}")

    # æƒ…ç»ªåˆ†å¸ƒç»Ÿè®¡ + å¯è§†åŒ–
    if emotions:
        emo_counts = Counter(emotions)
        total = len(emotions)
        print("\nğŸ“Š æƒ…ç»ªåˆ†å¸ƒç»Ÿè®¡ï¼š")
        for emo, cnt in sorted(emo_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"  {emo:12} : {cnt:2d} ({cnt/total*100:.1f}%)")

        # æŸ±çŠ¶å›¾
        plt.figure(figsize=(10, 6))
        labels, counts = zip(*emo_counts.most_common())
        plt.bar(labels, counts, color='skyblue', alpha=0.7)
        plt.title(f"SenseVoiceSmall Emotion Distribution\n({total} utterances)")
        plt.xlabel("Emotion")
        plt.ylabel("Count")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(OUTPUT_PLOT, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… åˆ†å¸ƒå›¾: {OUTPUT_PLOT}")

    print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼æ£€æŸ¥ JSON/CSV ä¸­çš„ transcriptionï¼ŒéªŒè¯æƒ…ç»ªæ˜¯å¦åŒ¹é…å†…å®¹ã€‚")
    print("å¦‚æœ emotion éƒ½æ˜¯ 'unknown'ï¼Œè¯´æ˜éŸ³é¢‘ä¸­æ€§æˆ–éœ€è°ƒæ•´é˜ˆå€¼ã€‚")

if __name__ == "__main__":
    main()